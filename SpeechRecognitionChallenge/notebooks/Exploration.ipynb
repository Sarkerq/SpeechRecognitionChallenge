{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import hashlib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import IPython.display as ipd\n",
    "import cProfile\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "\n",
    "from tensorflow.python.keras.layers import Input, Dense, LSTM\n",
    "\n",
    "from tensorflow.python.keras.layers import Embedding, Dropout, Activation\n",
    "from tensorflow.python.keras.layers import BatchNormalization\n",
    "import sys\n",
    "sys.path.insert(0, '../src/data')\n",
    "import get_train_test\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from itertools import product\n",
    "import cnn_utils\n",
    "\n",
    "\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from SGDRScheduler import SGDRScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras gpu options\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "#config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "                                    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 : 8.980920599729721 s\n",
      "2000 : 15.26527488432811 s\n",
      "3000 : 22.481125728103162 s\n",
      "4000 : 28.889359498961642 s\n",
      "5000 : 35.160310695639545 s\n",
      "6000 : 41.40774187301897 s\n",
      "7000 : 47.10674593374026 s\n",
      "8000 : 52.583841299562096 s\n",
      "9000 : 58.027167612034965 s\n",
      "10000 : 63.466431972457 s\n",
      "11000 : 68.96417556034918 s\n",
      "12000 : 74.45383093647666 s\n",
      "13000 : 80.43878189848772 s\n",
      "14000 : 86.29197070110416 s\n",
      "15000 : 92.69032548949784 s\n",
      "16000 : 98.30019388733858 s\n",
      "17000 : 105.30292947932675 s\n",
      "18000 : 111.21089001919181 s\n",
      "19000 : 117.15116853429213 s\n",
      "20000 : 122.6452468884077 s\n",
      "21000 : 128.13560790613982 s\n",
      "22000 : 133.70808017073244 s\n",
      "23000 : 139.170041165162 s\n",
      "24000 : 144.67104752496206 s\n",
      "25000 : 150.17331501400207 s\n",
      "26000 : 152.01433149893867 s\n",
      "27000 : 153.50729231367575 s\n",
      "28000 : 155.02397335300378 s\n",
      "29000 : 156.53389336114327 s\n",
      "30000 : 158.0716940075438 s\n",
      "31000 : 159.61757671185782 s\n",
      "32000 : 161.17514598986338 s\n"
     ]
    }
   ],
   "source": [
    "raw_train, raw_dev = get_train_test.get_train_test('../data/raw/train/audio/',10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 161)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train = np.array([np.pad(x[0], ((0,99 - x[0].shape[0]),(0,0)), 'constant', constant_values=(0)) for x in raw_train])\n",
    "x_dev = np.array([np.pad(x[0], ((0,99 - x[0].shape[0]),(0,0)), 'constant', constant_values=(0)) for x in raw_dev])\n",
    "\n",
    "y_train = np.array([x[1] for x in raw_train])\n",
    "y_dev = np.array([x[1] for x in raw_dev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29220, 99, 161)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unk_train = np.where(y_train == 'unknown')[0]\n",
    "unk_dev = np.where(y_dev == 'unknown')[0]\n",
    "\n",
    "np.random.seed(42)\n",
    "# unk_train_downsampled = np.random.choice(unk_train, size=unk_train.shape[0] - int(x_train.shape[0]/27), replace=False)\n",
    "unk_dev_downsampled = np.random.choice(unk_dev, size=unk_dev.shape[0] - int(x_dev.shape[0]/27), replace=False)\n",
    "\n",
    "# all_train_index = np.where(y_train)[0]\n",
    "all_dev_index = np.where(y_dev)[0]\n",
    "\n",
    "# downsampled_train_index = np.setdiff1d(all_train_index,unk_train_downsampled)\n",
    "downsampled_dev_index = np.setdiff1d(all_dev_index,unk_dev_downsampled)\n",
    "\n",
    "# x_train = x_train[downsampled_train_index]\n",
    "x_dev_down = x_dev[downsampled_dev_index]\n",
    "\n",
    "# y_train = y_train[downsampled_train_index]\n",
    "y_dev_down = y_dev[downsampled_dev_index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1,99,161,1)\n",
    "x_dev_down = x_dev_down.reshape(-1,99,161,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate([x_train,x_train,x_train],axis = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29220, 99, 161, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev_down = np.concatenate([x_dev_down,x_dev_down,x_dev_down],axis = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1255, 99, 161, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dev_down.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_norm(x_train, x_val, x_ens = None, x_test = None):\n",
    "    print(\"FUP\")\n",
    "    mean = np.mean(x_train, axis=(0, 1, 2, 3))\n",
    "    std = np.std(x_train, axis=(0, 1, 2, 3))\n",
    "    x_train = (x_train - mean) / (std + 1e-7)\n",
    "    x_val = (x_val - mean) / (std + 1e-7)\n",
    "    if x_ens != None:\n",
    "        x_ens = (x_ens - mean) / (std + 1e-7)\n",
    "    if x_test != None:\n",
    "        x_test = (x_test - mean) / (std + 1e-7)\n",
    "    return x_train, x_val, x_ens, x_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#x_train_norm, x_val_norm, _, _ = z_norm(x_train,x_dev_down)\n",
    "#x_train, x_dev_down, _, _ = cnn_utils.preprocess_res(x_train,x_dev_down)\n",
    "x_train, x_dev_down, _, _ = cnn_utils.preprocess_mob(x_train,x_dev_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels_to_keep = ['yes', 'no', 'up', 'down', 'left',\n",
    "                    'right', 'on', 'off', 'stop', 'go', 'silence']\n",
    "\n",
    "for label in labels_to_keep + ['unknown']:\n",
    "    print (f\"{label} dev count: {len([x for x in np.array([x[1] for x in raw_dev ]) if x == label])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0: 37,\n",
    "                1: 37,\n",
    "                2: 37,\n",
    "                3: 37,\n",
    "                4: 37,\n",
    "                5: 37,\n",
    "                6: 37,\n",
    "                7: 37,\n",
    "                8: 2,\n",
    "                9: 37,\n",
    "                10: 37}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 37, 1: 37, 2: 37, 3: 37, 4: 37, 5: 37, 6: 37, 7: 37, 8: 2, 9: 37, 10: 37}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_resh = x_train.reshape(-1, 99*161)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(x_resh)\n",
    "\n",
    "x_train_scaled = scaler.transform(x_resh).reshape(-1,99,161,1)\n",
    "x_dev_scaled = scaler.transform(x_dev_down.reshape(-1,99*161)).reshape(-1,99,161,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat = to_categorical(OrdinalEncoder().fit_transform(y_train.reshape(-1,1)))\n",
    "y_dev_cat = to_categorical(OrdinalEncoder().fit_transform(y_dev_down.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights,name=\"weights\").initialized_value()\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "weights = np.ones(11)\n",
    "\n",
    "weights[8] = (2/37) * (10/8)\n",
    "\n",
    "wcc = weighted_categorical_crossentropy(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='./model-{val_acc:.3f}.hdf5', monitor='val_acc', verbose=1, save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29220"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size = x_train_scaled.shape[0]\n",
    "batch_size = 1024\n",
    "schedule = SGDRScheduler(min_lr=1e-5,\n",
    "                                     max_lr=3e-3,\n",
    "                                     steps_per_epoch=np.ceil(epoch_size/batch_size),\n",
    "                                     lr_decay=0.9,\n",
    "                                     cycle_length=5,\n",
    "                                     mult_factor=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29220 samples, validate on 1255 samples\n",
      "Epoch 1/50\n",
      "28672/29220 [============================>.] - ETA: 1s - loss: 2.1395 - categorical_accuracy: 0.1372\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.19681, saving model to ./model-0.197.hdf5\n",
      "29220/29220 [==============================] - 70s 2ms/step - loss: 2.1304 - categorical_accuracy: 0.1378 - val_loss: 2.2574 - val_categorical_accuracy: 0.1968\n",
      "Epoch 2/50\n",
      "28672/29220 [============================>.] - ETA: 1s - loss: 1.5745 - categorical_accuracy: 0.1953\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.19681 to 0.27092, saving model to ./model-0.271.hdf5\n",
      "29220/29220 [==============================] - 57s 2ms/step - loss: 1.5713 - categorical_accuracy: 0.1961 - val_loss: 2.0509 - val_categorical_accuracy: 0.2709\n",
      "Epoch 3/50\n",
      "28672/29220 [============================>.] - ETA: 1s - loss: 1.2306 - categorical_accuracy: 0.2976\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.27092 to 0.34422, saving model to ./model-0.344.hdf5\n",
      "29220/29220 [==============================] - 58s 2ms/step - loss: 1.2286 - categorical_accuracy: 0.2994 - val_loss: 1.8755 - val_categorical_accuracy: 0.3442\n",
      "Epoch 4/50\n",
      "28672/29220 [============================>.] - ETA: 1s - loss: 1.0054 - categorical_accuracy: 0.4001\n",
      "Epoch 00004: val_categorical_accuracy improved from 0.34422 to 0.47092, saving model to ./model-0.471.hdf5\n",
      "29220/29220 [==============================] - 61s 2ms/step - loss: 1.0041 - categorical_accuracy: 0.4008 - val_loss: 1.5519 - val_categorical_accuracy: 0.4709\n",
      "Epoch 5/50\n",
      "28672/29220 [============================>.] - ETA: 1s - loss: 0.8697 - categorical_accuracy: 0.4941\n",
      "Epoch 00005: val_categorical_accuracy improved from 0.47092 to 0.58884, saving model to ./model-0.589.hdf5\n",
      "29220/29220 [==============================] - 69s 2ms/step - loss: 0.8696 - categorical_accuracy: 0.4951 - val_loss: 1.2471 - val_categorical_accuracy: 0.5888\n",
      "Epoch 6/50\n",
      "28672/29220 [============================>.] - ETA: 1s - loss: 0.7348 - categorical_accuracy: 0.5628\n",
      "Epoch 00006: val_categorical_accuracy improved from 0.58884 to 0.66614, saving model to ./model-0.666.hdf5\n",
      "29220/29220 [==============================] - 65s 2ms/step - loss: 0.7361 - categorical_accuracy: 0.5629 - val_loss: 1.0321 - val_categorical_accuracy: 0.6661\n",
      "Epoch 7/50\n",
      "17408/29220 [================>.............] - ETA: 24s - loss: 0.6626 - categorical_accuracy: 0.6313"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-f7a94e10250f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m model.fit(x_train_scaled.reshape(-1,99,161),y_train_cat, batch_size = 1024, epochs = 50, shuffle = True,class_weight=class_weight,\n\u001b[1;32m---> 29\u001b[1;33m                         validation_data=(x_dev_scaled.reshape(-1,99,161),y_dev_cat), callbacks=[checkpointer])\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1603\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1605\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    212\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m           \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2976\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2977\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 2978\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   2979\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2980\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1399\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1400\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(110, return_sequences=True, input_shape=(99,161)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(110, return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(110, return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(110, return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(110, return_sequences=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(110))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(110))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(11))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',  optimizer='adam',metrics=['categorical_accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./model-{val_categorical_accuracy:.3f}.hdf5', monitor='val_categorical_accuracy', verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "model.fit(x_train_scaled.reshape(-1,99,161),y_train_cat, batch_size = 1024, epochs = 50, shuffle = True,class_weight=class_weight,\n",
    "                        validation_data=(x_dev_scaled.reshape(-1,99,161),y_dev_cat), callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet_model = cnn_utils.get_aml_model(x_train_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size = x_train_scaled.shape[0]\n",
    "batch_size = 64\n",
    "schedule = SGDRScheduler(min_lr=1e-5,\n",
    "                                     max_lr=3e-3,\n",
    "                                     steps_per_epoch=np.ceil(epoch_size/batch_size),\n",
    "                                     lr_decay=0.9,\n",
    "                                     cycle_length=5,\n",
    "                                     mult_factor=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29220 samples, validate on 1255 samples\n",
      "Epoch 1/50\n",
      " 6336/29220 [=====>........................] - ETA: 6:05 - loss: 23.2644 - acc: 0.5663"
     ]
    }
   ],
   "source": [
    "resnet_model.fit(x_train_scaled,y_train_cat, batch_size = 64, epochs = 50, shuffle = True,class_weight=class_weight,\n",
    "                        validation_data=(x_dev_scaled,y_dev_cat), callbacks=[schedule, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./model-0.98.hdf5', custom_objects={'loss': wcc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_dev_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8     155\n",
       "1     134\n",
       "4     124\n",
       "5     113\n",
       "3     113\n",
       "10    111\n",
       "7     108\n",
       "6     105\n",
       "0     103\n",
       "2      99\n",
       "9      90\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pred = resnet_model.predict(x_dev_scaled)\n",
    "\n",
    "x_best_pred = np.argmax(x_pred,axis=1)\n",
    "\n",
    "pd.DataFrame(x_best_pred.reshape(-1,1))[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = model.predict(x_dev_scaled)\n",
    "\n",
    "x_best_pred = np.argmax(x_pred,axis=1)\n",
    "\n",
    "pd.DataFrame(x_best_pred.reshape(-1,1))[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_dev.reshape(-1,1))[0].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
