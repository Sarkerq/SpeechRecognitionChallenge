{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import hashlib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import IPython.display as ipd\n",
    "import cProfile\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "\n",
    "from tensorflow.python.keras.layers import Input, Dense, LSTM\n",
    "\n",
    "from tensorflow.python.keras.layers import Embedding, Dropout, Activation\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../src/data')\n",
    "import get_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 : 2.8701734851995298 s\n",
      "2000 : 4.307397869701845 s\n",
      "3000 : 5.782134064465254 s\n",
      "4000 : 7.226360297994006 s\n",
      "5000 : 8.675331148853957 s\n"
     ]
    }
   ],
   "source": [
    "raw_train, raw_dev = get_train_test.get_train_test('../data/raw/train/audio/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 161)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train = np.array([np.pad(x[0], ((0,99 - x[0].shape[0]),(0,0)), 'constant', constant_values=(0)) for x in raw_train])\n",
    "x_dev = np.array([np.pad(x[0], ((0,99 - x[0].shape[0]),(0,0)), 'constant', constant_values=(0)) for x in raw_dev])\n",
    "\n",
    "y_train = np.array([x[1] for x in raw_train])\n",
    "y_dev = np.array([x[1] for x in raw_dev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes dev count: 180\n",
      "no dev count: 179\n",
      "up dev count: 178\n",
      "down dev count: 174\n",
      "left dev count: 175\n",
      "right dev count: 181\n",
      "on dev count: 174\n",
      "off dev count: 176\n",
      "stop dev count: 177\n",
      "go dev count: 181\n",
      "silence dev count: 0\n",
      "unknown dev count: 3107\n"
     ]
    }
   ],
   "source": [
    "labels_to_keep = ['yes', 'no', 'up', 'down', 'left',\n",
    "                    'right', 'on', 'off', 'stop', 'go', 'silence']\n",
    "\n",
    "for label in labels_to_keep + ['unknown']:\n",
    "    print (f\"{label} dev count: {len([x for x in raw_train if x[1] == label])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0: 37,\n",
    "                1: 37,\n",
    "                2: 37,\n",
    "                3: 37,\n",
    "                4: 37,\n",
    "                5: 37,\n",
    "                6: 37,\n",
    "                7: 37,\n",
    "                8: 2,\n",
    "                9: 37,\n",
    "                10: 37}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_resh = x_train.reshape(-1, 99*161)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(x_resh)\n",
    "\n",
    "x_train_scaled = scaler.transform(x_resh).reshape(-1,99,161)\n",
    "x_dev_scaled = scaler.transform(x_dev.reshape(-1,99*161)).reshape(-1,99,161)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4882 samples, validate on 512 samples\n",
      "Epoch 1/50\n",
      "4096/4882 [========================>.....] - ETA: 5s - loss: 2.8548 - categorical_accuracy: 0.1228 \n",
      "Epoch 00001: saving model to ./model-01.hdf5\n",
      "4882/4882 [==============================] - 42s 9ms/step - loss: 2.7953 - categorical_accuracy: 0.1274 - val_loss: 2.4000 - val_categorical_accuracy: 0.0918\n",
      "Epoch 2/50\n",
      "4096/4882 [========================>.....] - ETA: 4s - loss: 2.1969 - categorical_accuracy: 0.1501\n",
      "Epoch 00002: saving model to ./model-02.hdf5\n",
      "4882/4882 [==============================] - 27s 6ms/step - loss: 2.1825 - categorical_accuracy: 0.1477 - val_loss: 2.3898 - val_categorical_accuracy: 0.2344\n",
      "Epoch 3/50\n",
      "4096/4882 [========================>.....] - ETA: 3s - loss: 1.9322 - categorical_accuracy: 0.1602\n",
      "Epoch 00003: saving model to ./model-03.hdf5\n",
      "4882/4882 [==============================] - 26s 5ms/step - loss: 1.9155 - categorical_accuracy: 0.1630 - val_loss: 2.3676 - val_categorical_accuracy: 0.1895\n",
      "Epoch 4/50\n",
      "4096/4882 [========================>.....] - ETA: 3s - loss: 1.7342 - categorical_accuracy: 0.1885\n",
      "Epoch 00004: saving model to ./model-04.hdf5\n",
      "4882/4882 [==============================] - 27s 5ms/step - loss: 1.7332 - categorical_accuracy: 0.1844 - val_loss: 2.3479 - val_categorical_accuracy: 0.1641\n",
      "Epoch 5/50\n",
      "3072/4882 [=================>............] - ETA: 8s - loss: 1.5448 - categorical_accuracy: 0.2142 "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(110, return_sequences=True, input_shape=(99,161)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(110, return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(110, return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(110, return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(110, return_sequences=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(110))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(110))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(11))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./model-{epoch:02d}.hdf5', verbose=1)\n",
    "\n",
    "y_train_cat = to_categorical(OrdinalEncoder().fit_transform(y_train.reshape(-1,1)))\n",
    "y_dev_cat = to_categorical(OrdinalEncoder().fit_transform(y_dev.reshape(-1,1)))\n",
    "\n",
    "model.fit(x_train_scaled,y_train_cat, batch_size = 1024, epochs = 50,\n",
    "                        validation_data=(x_dev_scaled,y_dev_cat), callbacks=[checkpointer], class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    316\n",
       "2    181\n",
       "8      8\n",
       "4      7\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pred = model.predict(x_dev)\n",
    "\n",
    "x_best_pred = np.argmax(x_pred,axis=1)\n",
    "\n",
    "pd.DataFrame(x_best_pred.reshape(-1,1))[0].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
