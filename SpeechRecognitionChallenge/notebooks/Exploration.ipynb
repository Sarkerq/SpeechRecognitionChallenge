{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import hashlib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import IPython.display as ipd\n",
    "import cProfile\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "\n",
    "from tensorflow.python.keras.layers import Input, Dense, LSTM\n",
    "\n",
    "from tensorflow.python.keras.layers import Embedding, Dropout, Activation\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../src/data')\n",
    "import get_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 : 1.4626410103142606 s\n",
      "200 : 1.6053225047476944 s\n",
      "300 : 1.7623445178849304 s\n",
      "400 : 1.9202329929160997 s\n",
      "500 : 2.060560435101717 s\n",
      "600 : 2.1993518766571802 s\n",
      "700 : 2.3425187046230582 s\n",
      "800 : 2.4827177364995845 s\n",
      "900 : 2.6200289723195787 s\n",
      "1000 : 3.1510527799190893 s\n",
      "1100 : 3.680545920223967 s\n",
      "1200 : 4.213536497861127 s\n",
      "1300 : 4.738521738880713 s\n",
      "1400 : 5.290853862914405 s\n",
      "1500 : 5.824255927899867 s\n",
      "1600 : 6.372203639878416 s\n",
      "1700 : 6.930178432893715 s\n",
      "1800 : 7.493927176995765 s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-db3003d0fbdb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mraw_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_dev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_train_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_train_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/raw/train/audio/'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\MGU\\SpeechRecognitionChallenge\\SpeechRecognitionChallenge\\src\\data\\get_train_test.py\u001b[0m in \u001b[0;36mget_train_test\u001b[1;34m(train_audio_path, val_perc, portion)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mwhich\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwhich_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{train_audio_path}/{filename}\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_perc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_perc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0msample_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwavfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_audio_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m         \u001b[1;31m#if len(samples) != 8000 :\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;31m#    continue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\scipy\\io\\wavfile.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(filename, mmap)\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[0mmmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raw_train, raw_dev = get_train_test.get_train_test('../data/raw/train/audio/',10,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 161)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train = np.array([np.pad(x[0], ((0,99 - x[0].shape[0]),(0,0)), 'constant', constant_values=(0)) for x in raw_train])\n",
    "x_dev = np.array([np.pad(x[0], ((0,99 - x[0].shape[0]),(0,0)), 'constant', constant_values=(0)) for x in raw_dev])\n",
    "\n",
    "y_train = np.array([x[1] for x in raw_train])\n",
    "y_dev = np.array([x[1] for x in raw_dev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4882, 99, 161)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_train = np.where(y_train == 'unknown')[0]\n",
    "unk_dev = np.where(y_dev == 'unknown')[0]\n",
    "\n",
    "np.random.seed(42)\n",
    "unk_train_downsampled = np.random.choice(unk_train, size=unk_train.shape[0] - int(x_train.shape[0]/27), replace=False)\n",
    "unk_dev_downsampled = np.random.choice(unk_dev, size=unk_dev.shape[0] - int(x_dev.shape[0]/27), replace=False)\n",
    "\n",
    "all_train_index = np.where(y_train)[0]\n",
    "all_dev_index = np.where(y_dev)[0]\n",
    "\n",
    "downsampled_train_index = np.setdiff1d(all_train_index,unk_train_downsampled)\n",
    "downsampled_dev_index = np.setdiff1d(all_dev_index,unk_dev_downsampled)\n",
    "\n",
    "x_train = x_train[downsampled_train_index]\n",
    "x_dev = x_dev[downsampled_dev_index]\n",
    "\n",
    "y_train = y_train[downsampled_train_index]\n",
    "y_dev = y_dev[downsampled_dev_index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes dev count: 18\n",
      "no dev count: 19\n",
      "up dev count: 20\n",
      "down dev count: 23\n",
      "left dev count: 21\n",
      "right dev count: 17\n",
      "on dev count: 23\n",
      "off dev count: 21\n",
      "stop dev count: 21\n",
      "go dev count: 17\n",
      "silence dev count: 0\n",
      "unknown dev count: 18\n"
     ]
    }
   ],
   "source": [
    "labels_to_keep = ['yes', 'no', 'up', 'down', 'left',\n",
    "                    'right', 'on', 'off', 'stop', 'go', 'silence']\n",
    "\n",
    "for label in labels_to_keep + ['unknown']:\n",
    "    print (f\"{label} dev count: {len([x for x in np.array([x[1] for x in raw_dev ])[downsampled_dev_index] if x == label])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0: 37,\n",
    "                1: 37,\n",
    "                2: 37,\n",
    "                3: 37,\n",
    "                4: 37,\n",
    "                5: 37,\n",
    "                6: 37,\n",
    "                7: 37,\n",
    "                8: 2,\n",
    "                9: 37,\n",
    "                10: 37}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_resh = x_train.reshape(-1, 99*161)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(x_resh)\n",
    "\n",
    "x_train_scaled = scaler.transform(x_resh).reshape(-1,99,161)\n",
    "x_dev_scaled = scaler.transform(x_dev.reshape(-1,99*161)).reshape(-1,99,161)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "rand_perm = np.random.permutation(x_train_scaled.shape[0])\n",
    "x_train_scaled = x_train_scaled[rand_perm]\n",
    "y_train_cat = y_train_cat[rand_perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4882 samples, validate on 512 samples\n",
      "Epoch 1/50\n",
      "4096/4882 [========================>.....] - ETA: 7s - loss: 2.9420 - categorical_accuracy: 0.0986 \n",
      "Epoch 00001: saving model to ./model-01.hdf5\n",
      "4882/4882 [==============================] - 60s 12ms/step - loss: 2.9014 - categorical_accuracy: 0.0965 - val_loss: 2.4034 - val_categorical_accuracy: 0.0605\n",
      "Epoch 2/50\n",
      "4096/4882 [========================>.....] - ETA: 5s - loss: 2.4471 - categorical_accuracy: 0.1011 \n",
      "Epoch 00002: saving model to ./model-02.hdf5\n",
      "4882/4882 [==============================] - 35s 7ms/step - loss: 2.4422 - categorical_accuracy: 0.0991 - val_loss: 2.4036 - val_categorical_accuracy: 0.0547\n",
      "Epoch 3/50\n",
      "4096/4882 [========================>.....] - ETA: 5s - loss: 2.2972 - categorical_accuracy: 0.1016 \n",
      "Epoch 00003: saving model to ./model-03.hdf5\n",
      "4882/4882 [==============================] - 33s 7ms/step - loss: 2.3003 - categorical_accuracy: 0.0989 - val_loss: 2.4004 - val_categorical_accuracy: 0.0840\n",
      "Epoch 4/50\n",
      "4096/4882 [========================>.....] - ETA: 5s - loss: 2.1745 - categorical_accuracy: 0.1155 \n",
      "Epoch 00004: saving model to ./model-04.hdf5\n",
      "4882/4882 [==============================] - 35s 7ms/step - loss: 2.1775 - categorical_accuracy: 0.1155 - val_loss: 2.4002 - val_categorical_accuracy: 0.0527\n",
      "Epoch 5/50\n",
      "4096/4882 [========================>.....] - ETA: 5s - loss: 2.0689 - categorical_accuracy: 0.1377 \n",
      "Epoch 00005: saving model to ./model-05.hdf5\n",
      "4882/4882 [==============================] - 35s 7ms/step - loss: 2.0791 - categorical_accuracy: 0.1327 - val_loss: 2.3992 - val_categorical_accuracy: 0.0645\n",
      "Epoch 6/50\n",
      "4096/4882 [========================>.....] - ETA: 5s - loss: 1.9470 - categorical_accuracy: 0.1663 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-2010e0641c8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m model.fit(x_train_scaled,y_train_cat, batch_size = 1024, epochs = 50,\n\u001b[1;32m---> 27\u001b[1;33m                         validation_data=(x_dev_scaled,y_dev_cat), callbacks=[checkpointer],class_weight=class_weight)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1603\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1605\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    212\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m           \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2976\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2977\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 2978\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   2979\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2980\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1399\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1400\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(110, return_sequences=True, input_shape=(99,161)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(110, return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(110, return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(110, return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(110, return_sequences=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(110))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(110))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(11))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./model-{epoch:02d}.hdf5', verbose=1)\n",
    "\n",
    "y_train_cat = to_categorical(OrdinalEncoder().fit_transform(y_train.reshape(-1,1)))\n",
    "y_dev_cat = to_categorical(OrdinalEncoder().fit_transform(y_dev.reshape(-1,1)))\n",
    "\n",
    "model.fit(x_train_scaled,y_train_cat, batch_size = 1024, epochs = 50,\n",
    "                        validation_data=(x_dev_scaled,y_dev_cat), callbacks=[checkpointer],class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8     403\n",
       "2      56\n",
       "7      14\n",
       "10     11\n",
       "4       9\n",
       "9       7\n",
       "1       6\n",
       "3       3\n",
       "6       1\n",
       "5       1\n",
       "0       1\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pred = model.predict(x_dev_scaled)\n",
    "\n",
    "x_best_pred = np.argmax(x_pred,axis=1)\n",
    "\n",
    "pd.DataFrame(x_best_pred.reshape(-1,1))[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
